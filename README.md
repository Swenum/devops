### Настройка SSH-Agent
Генерируем пару ключей коммандой:
ssh-keygen -t ed25519 -C "your_email@example.com"

#### Добавляем строчку в

```.bashrc 
eval `ssh-agent`
```
и перевходим в систему.

#### Загружаем ключ в агента:
```bash
ssh-add ~/.ssh/kurs_devops2025
```
#### Проверяем
```bash
ssh -T git@github.com
# Attempts to ssh to GitHub
```
#### Добавляем данные для коммитера
```bash
git config --global user.email "you@example.com"
git config --global user.name "Your Name"
```
#### Работа с ветками:
```bash
# СОздать ветку
$ git branch <name of new branch>
# Перейти в ветку
$ git checkout <name of branch>
```

#### История кооммитов
```bash
git log --graph
```

#### Разница между двумя коммитами
```bash
git diff id-commit id2-commit
```
### HW1

1. Найти топ 7 директорий на сервере, которые больше всего занимают память и записать их в файл.


```bash

#!/bin/bash


output_file="top_directories.txt"

# Получаем топ-7 директорий, занимающих больше всего места
du -ah / | sort -rh | head -n 7 > "$output_file"


echo "Топ-7 директорий, занимающих больше всего места, записан в файл $output_file"

```

2. Создать пользователя и добавить его в группу sudo.

```bash
USER='u.schuka'
useradd -m "$USER"
mkdir -p /home/"$USER"/.ssh
# Добавляем ключ в файл authorized_keys
echo "ssh-ed448 AAAACXNzaC1lZDQ0OAAAADlL4ph5NNzIe+vjO6E/NzfGkJXtAzhx7AJ4G/a6QiLp1K6CZdbeoTrVRCX0zcBOFdaxZaImZ/qmhQA= eddsa-key-my" >> /home/"$USER"/.ssh/authorized_keys
# Меняем владельца директории
chown "$USER":"$USER" /home/"$USER" -R
# Назначаем права, ограничивая доступ только владельцу
chmod 600 /home/"$USER"/.ssh/authorized_keys
chmod 700 /home/"$USER"/.ssh
# Добавляем в группу sudo
usermod -G sudo "$USER"
# Изменяем оболочку
usermod -s /bin/bash "$USER"
```


3. Изучить, что такое zombie процесс (спрашивают на собесах).
```
Процесс при завершении (как нормальном, так и в результате не обрабатываемого сигнала) освобождает все свои ресурсы и становится «зомби» — пустой записью в таблице процессов, хранящей статус завершения, предназначенный для чтения родительским процессом.

Зомби-процесс существует до тех пор, пока родительский процесс не прочитает его статус с помощью системного вызова wait(), в результате чего запись в таблице процессов будет освобождена.

При завершении процесса система уведомляет родительский процесс о завершении дочернего с помощью сигнала SIGCHLD, таким образом может быть удобно (но не обязательно) осуществлять вызов wait() в обработчике данного сигнала. 

Процесс-сирота (англ. orphan process) — в семействе операционных систем UNIX вспомогательный процесс, чей основной процесс (или связь с ним) был завершен нештатно (не подав сигнала на завершение работы).

Обычно «сиротой» остается дочерний процесс после неожиданного завершения родительского, но возможно возникновение сервера-сироты (локального или сетевого) при неожиданном прерывании связи или завершении клиентского процесса.

Процессы-сироты расходуют системные ресурсы сервера и могут быть источником проблем. Существует несколько их решений:

    Уничтожение (англ. extermination) заключается в завершении процесса (например, посылкой сигнала SIGTERM или SIGKILL), используется наиболее часто (особенно оператором, обслуживающим систему).
    Перевоплощение (англ. reincarnation) — система пытается «воскресить» родителей в состоянии на момент перед их удалением или найти других (например, более старших) родителей.
    Выдача лимита времени (англ. expiration) — процессу выдаётся временная квота для завершения до момента, когда он будет «убит» принудительно. Отметим, что процессу оставлена возможность запросить дополнительное время для завершения.

В Unix-подобных системах все процессы-сироты немедленно усыновляются специальным системным процессом «init». Эта операция ещё называется переподчинением (англ. reparenting) и происходит автоматически. Хотя технически процесс «init» признаётся родителем этого процесса, его всё равно считают «осиротевшим», поскольку первоначально создавший его процесс более не существует. 
```
### Для увеличения количества максимума открытых файлов

```bash
$ ulimit -Sn
$ ulimit -Hn
# sysctl -w fs.file-max=500000
cat /proc/sys/fs/file-max
```
```/etc/sysctl.conf
fs.file-max=500000
```
```bash
# sysctl -p
```
4. Изучить, что показывает команда top.

```
Команда top в Unix-подобных операционных системах (например, Linux) показывает динамическую информацию о работающих процессах и общем состоянии системы в реальном времени. Вот что она отображает:

    Общая информация о системе:

        Время работы системы (uptime).

        Количество пользователей, подключенных к системе.

        Средняя загрузка системы за последние 1, 5 и 15 минут.

    Информация о задачах (процессах):

        Общее количество процессов.

        Количество запущенных, спящих, остановленных и зомби-процессов.

    Информация о использовании ресурсов:

        Использование процессора (CPU): процент времени, затраченного на выполнение пользовательских процессов, системных процессов, процессов с измененным приоритетом (nice), а также время простоя (idle).

        Использование оперативной памяти (RAM): общий объем, используемый объем, свободный объем, а также объем памяти, используемый для кэширования.

        Использование подкачки (swap): общий объем, используемый объем и свободный объем.

    Список процессов:

        PID (идентификатор процесса).

        Пользователь, от имени которого запущен процесс.

        Приоритет (PR) и значение nice (NI).

        Использование виртуальной памяти (VIRT), резидентной памяти (RES), разделяемой памяти (SHR).

        Процент использования процессора (%CPU) и памяти (%MEM).

        Время работы процесса (TIME+).

        Команда, запустившая процесс.

    Интерактивные команды:

        top позволяет управлять отображением и сортировкой процессов с помощью клавиш (например, P для сортировки по использованию CPU, M для сортировки по использованию памяти, k для завершения процесса и т.д.).
```

### HW2



1. Написать скрипт, если в файле есть слово "error", тогда удалить этот файл.

```bash
#!/bin/bash
echo "Написать скрипт, если в файле есть слово "error", тогда удалить этот файл."
# Путь к файлу
file_to_check="your_file.txt"

# Проверяем, содержится ли слово "error" в файле
if grep -q "error" "$file_to_check"; then
  # Если слово "error" найдено, удаляем файл
  rm "$file_to_check"
  echo "Файл $file_to_check был удалён, так как содержит слово 'error'."
else
  echo "Слово 'error' не найдено в файле $file_to_check."
fi

```
#### Второй вариант
```bash
#!/bin/bash
# 
# grep -E 'error' -r ${PWD}/error/ | cut -d: -f1
# Создаём файл с содержимым:
echo "error" > error/file.txt
# Ищем в директории error/ отрезаем от вывода имя файла
grep -E 'error' -r ${PWD}/error/ | cut -d: -f1
# Выводим содержимое найденного файла перед удалением
#grep -E 'error' -r ${PWD}/error/ | cut -d: -f1 | xargs  cat
grep -E 'error' -r ${PWD}/error/ | cut -d: -f1 | xargs  rm
```

2. Написать скрипт, который будет создавать пользователя, имя пользователя должно вводится с клавиатуры.
Если пользователь существует, то вывести сообщение об этом.

```bash
#!/bin/bash -x
echo "Написать скрипт, который будет создавать пользователя, имя пользователя должно вводится с клавиатуры. Если пользователь существует, то вывести сообщение об этом."
# Запрос имени пользователя
read -p "Введите имя пользователя: " username
# Проверка существования пользователя
if id "$username" &>/dev/null; then
    echo "Пользователь '$username' уже существует."
else
    # Создание пользователя
    sudo useradd -m "$username"
    if [ $? -eq 0 ]; then
        echo "Пользователь '$username' успешно создан."
    else
        echo "Ошибка при создании пользователя '$username'."
    fi
fi
```



3. Что такое systemd ?

```
Systemd — это система инициализации и менеджер служб для операционных систем на базе Linux. Он предназначен для управления процессами и службами, упрощая запуск, остановку и мониторинг служб, а также их конфигурацию. Systemd стал стандартной системой инициализации для многих современных дистрибутивов Linux, таких как Fedora
, CentOS
, Ubuntu и Debian.
```

4. Написать любой сервис в линуксе.

```bash
[Unit]
Description=ROT13 demo service
After=network.target
StartLimitIntervalSec=0
[Service]
Type=simple
Restart=always
RestartSec=1
User=centos
ExecStart=/usr/bin/env bash /root/mycool_script.py

[Install]
WantedBy=multi-user.target
```

### HW3


1. Написать скрипт, пользователь вводит строку из букв и специальных символов в нижнем регистре и верхнем регистре. Нужно посчитать, сколько в этой строке больших букв.

```bash
#!/bin/bash
echo "Написать скрипт, пользователь вводит строку из букв и специальных символов в нижнем регистре и верхнем регистре. Нужно посчитать, сколько в этой строке больших букв."
# Запрос строки
read -p "Введите строку: " string
echo $string | sed -E 's/[[:lower:]]|[[:punct:]]|[[:space:]]//g' | wc -m


```


2. Написать скрипт, который будет делать ping google.com. Если сервер отвечает, то выводить - success, если нет - doesn't work.
```bash
#!/bin/bash
echo "Написать скрипт, который будет делать ping google.com. Если сервер отвечает, то выводить - success, если нет - doesn't work."
ping  10.11.1.55 -c 4
if [ $? -eq 0 ]
then
  echo "Ping was successful"
  exit 0
else
  echo "Ping doesn't work" 
  exit 1
fi
```

3. Написать скрипт, который будет выводить текущую дату и время.
```bash
date
```
### HW4

1. Выкачать свой репозиторий с помощью ssh способа.
   +
3. С помощью .gitignore, сделать так, чтобы все файлы *.txt не попадали в репозиторий.

```.gitignore
$GIT_DIR/hw2/error/*.txt
```
4. Изучить что такое git cherry-pick.
5. Продемонстрировать применение git cherry-pick на собственном репозитории (придумать любой пример).
6. Какая разница между git rebase и git merge ?

```
merge создаёт коммит слияния. И после merge остаются три удобных коммита. Чтобы продолжить используя только первую нить, только вторую нить, или все вместе.

коммит A ->
           |-> merge коммит C
коммит B ->

По сути merge создаёт историю.

А rebase меняет свою историю. Допустим вы написали свою работа D используя только видимую ветку коммит A.

         > работа D 
        /
коммит A ->
           |-> merge коммит C
коммит B ->

но передумали и перенесли всю свою работу в появившуюся ветку коммит B. И сделали rebase на коммит B :

коммит A ->
           |-> merge коммит C
коммит B ->
        \
         > работа D

или после rebase на коммит С :

коммит A ->
           |-> merge коммит C -> работа D
коммит B ->

rebase используют если хотят продолжить работу основываясь от чьей-то работы другого человека. Все коммиты вашей ветки работа D это новые коммиты, всё переписывается по-новой и забывается всё старое.

Линейность это то, что ваша работа D использует всё, что видно (A,B,C). Если использовать merge вместо rebase получится такой граф :

         > работа D             -> \
        /                           |-> merge D & C
коммит A ->                        / 
           |-> merge коммит C   -> 
коммит B ->

И есть возможность продолжать вашу ветку как без слияния так и с ним. rebase имеет разрушительное действие для истории. Если вы передумали пользоваться коммитом C то прийдется опять делать rebase.
```
7. Какая разница между git pull и git fetch ?
```
Команда git fetch загружает удаленное содержимое, но не изменяет состояние локального репозитория, в то время как git pull загружает удаленное содержимое и сразу пытается изменить состояние локального репозитория, чтобы оно соответствовало этому содержимому.
```
8. Что такое git submodule ?
```
Подмодуль git — это запись в хост-репозитории git, которая указывает на конкретный коммит в другом внешнем репозитории. Подмодули очень статичны: с их помощью можно отслеживать определенные коммиты, но не ветки или ссылки git. Кроме того, они не обновляются автоматически при обновлении хост-репозитория. Когда вы добавляете подмодуль в репозиторий, создается новый файл .gitmodules, в котором содержатся метаданные о сопоставлении URL-адреса проекта подмодуля с локальным каталогом. Если хост-репозиторий содержит несколько подмодулей, в файл .gitmodules будет включена отдельная запись для каждого подмодуля.
```
9. Изучить гит стратегии https://bool.dev/blog/detail/git-branching-strategies
10. Установить Docker на Ubuntu.

### HW5

1. Зарегистрироваться в Dockerhub.
2. Создать свой любой имадж(использовать Dockerfile) и запушить имадж в свой репозиторий в Dockerhub. Репозиторий сделать приватный.
```Dockerfile
# Stubby - Sends all outgoing DNS queries received on those addresses out over TLS

FROM ubuntu:jammy
LABEL maintainer="Uladzimir Schuka <wetoster@gmail.com>"
USER root

RUN sed -i -e 's/^APT/# APT/' -e 's/^DPkg/# DPkg/' \
      /etc/apt/apt.conf.d/docker-clean

RUN apt-get update && apt-get install -y \
    bash \
    bind9 \
    wget \
    automake \
    make \
    cmake \
    git \
    gcc \
    check\
    build-essential \
    libunbound-dev \
    libldns-dev \
    autoconf \
    libevent-dev \
    libuv1-dev \
    libev-dev \
    libssl-dev \
    libidn11-dev \
    libidn2-dev \
    libyaml-dev \
    ca-certificates && \
    rm -rf /var/lib/apt/lists/*

RUN set -x && \
    mkdir -p /tmp/src/getdns && \
    cd /tmp/src/getdns && \
    wget -O getdns.tar.gz https://getdnsapi.net/releases/getdns-1-7-3/getdns-1.7.3.tar.gz && \
    tar xzf getdns.tar.gz && \
    rm -f getdns.tar.gz && \
    cd getdns-1.7.3 && \
    groupadd getdns 
RUN  set -x && \
    cd /tmp/src/getdns/getdns-1.7.3 && \
    cmake -DENABLE_STUB_ONLY=ON  -DBUILD_TESTING=OFF . && \
    make && \
    rm -rf /tmp/* && \
    mkdir -p /opt/getdns/var/run/ && \
    chmod 777 /opt/getdns/var/run/
   


CMD ["/bin/bash", "-c", "read varname"]
#ENTRYPOINT ["tail", "-f", "/dev/null"]
```

```bash
# Cобираем образ, файлы берём из текущей директории
docker build .
docker login
```

3. Изучить разницу между CMD и Entrypoint.

```
В Dockerfile две важные инструкции, которые определяют, какой исполняемый файл будет запущен при старте контейнера, это `CMD` и `ENTRYPOINT`. Хотя обе инструкции выглядят похожими, между ними есть ключевые отличия в поведении и назначении.

Инструкция `CMD`

Задает команду и её аргументы по умолчанию, которые будут выполнены при запуске контейнера. Однако, если при запуске контейнера указаны любые другие команды, они заменят команду, заданную через него. Это делает его идеальным выбором для задания параметров по умолчанию, которые могут быть переопределены пользователем при запуске контейнера.

Пример:
```
```dockerfile
FROM ubuntu
CMD ["echo", "Hello, world!"]
```
```
При запуске этого контейнера без дополнительных параметров, будет выведено "Hello, world!". Но если при запуске указать другую команду, например `docker run <image> echo "Hello, Docker!"`, то будет выведено "Hello, Docker!".

Инструкция `ENTRYPOINT`

Конфигурирует контейнер так, что он будет запущен как исполняемый файл. Аргументы, указанные при запуске контейнера, передаются в него как дополнительные аргументы. Это означает, что команда, заданная в него, не заменяется, а дополняется аргументами, указанными при запуске контейнера.

Пример:
```
```dockerfile
FROM ubuntu
ENTRYPOINT ["echo", "Hello,"]
CMD ["world!"]
```
```
Здесь, если контейнер запущен без дополнительных аргументов, вывод будет "Hello, world!". Если же запустить контейнер с дополнительными аргументами, например `docker run <image> Docker`, то вывод будет "Hello, Docker".

Основные отличия

1. Переопределение команды: `CMD` может быть полностью переопределена при запуске контейнера, в то время как `ENTRYPOINT` предопределяет базовую команду, и любые аргументы, указанные при запуске, добавляются к этой команде.
2. Использование в комбинации: Часто `ENTRYPOINT` используется в комбинации с `CMD`, где `ENTRYPOINT` задает исполняемый файл, а `CMD` задает аргументы по умолчанию, которые могут быть переопределены при запуске.

`CMD` и `ENTRYPOINT` обе определяют, какая команда будет выполнена при запуске Docker-контейнера, но делают это по-разному. `CMD` лучше использовать для задания параметров по умолчанию, которые могут быть изменены, а `ENTRYPOINT` для установки фиксированной базовой команды, к которой можно добавлять аргументы.
```

### HW6

1. Через volume подкинуть конфиг в nginx контейнер, чтобы на страничке в браузере появилась слово Docker (либо через curl это проверить).


2. То же самое сделать через docker-compose.
```docker-compose
version: '2'

services:
  nginx:
    restart: always
    image: nginx:latest
    #image: dasskelett/nginx-quic

    hostname: man.swn.by man1.swn.by 
    ports:
      - "80:80/tcp"
      - "443:443/tcp"
      - "443:443/udp"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./letsencrypt:/etc/letsencrypt
      - ./config:/etc/nginx
      - ./www:/var/www/html 
      - ./files:/files
    environment:
      - LE_RENEW_HOOK=docker kill -s HUP @CONTAINER_NAME@
  certbot:
    image: certbot/certbot:latest
    volumes:
      - ./letsencrypt:/etc/letsencrypt
      - .letsencrypt_log:/var/log/letsencrypt/
    command: ["renew"]
```

### HW7

1. Развернуть Jenkins.
```docker-compose
services:
  jenkins:
    restart: always
    image: jenkins/jenkins:lts-jdk17
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - ./jenkins_home:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    networks:
      - cicd_network

  nexus:
    restart: always
    image: sonatype/nexus3
    ports:
      - "8081:8081"
      - "8083:8083"
    volumes:
      - nexus_data:/nexus-data
    networks:
      - cicd_network
volumes:
  nexus_data:
    external: true
    name: nexus_data


networks:
    cicd_network:
        driver: bridge


```
2. Подключить Linux Slave к Jenkins.

3. Создать Jenkins pipeline, pipeline должен уметь разворачивать ELK stack. Если не хватает ресурсов, тогда развернуть только Elasticsearch.
   ELK стек должен разворачиваться на новом слейве.

